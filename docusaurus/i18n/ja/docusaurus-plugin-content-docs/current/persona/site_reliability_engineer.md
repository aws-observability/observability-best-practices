# サイト信頼性エンジニア

サイト信頼性エンジニアリング (SRE) は、ソフトウェアシステムの信頼性とパフォーマンスの向上に焦点を当てたソフトウェアエンジニアリングの実践です。SRE の主要な目標の 1 つは、可用性、パフォーマンス、レイテンシー、効率性、容量、インシデント対応などの領域でソフトウェアシステムの信頼性を向上させることです。SRE チームが目標に対して検証するために測定する指標には、サービスレベルアグリーメント (SLA)、サービスレベル目標 (SLO)、サービスレベルインジケーター (SLI)、エラーバジェットなどがあります。

以下は、オブザーバビリティ戦略を導くための SRE の重点領域とベストプラクティスです。 

## インシデント対応と危機管理
インシデント対応には、監視、検出、および計画外のイベントや中断への対応が含まれ、インシデントの平均解決時間 (MTTR) を最小化し、サービスレベルアグリーメント (SLA) を満たすことを目標としています。 

### インシデント対応と危機管理に関するベストプラクティスには、以下のようなものがあります。
- 迅速な検出、対応、封じ込めは、インシデントを最小限の時間で軽減し、さらなる影響を回避するために不可欠です。

- オンコールスケジュールを合理化し、効果的なインシデント軽減のための運用ランブックを組み込むことで、堅牢なオンコールシステムを構築します。

- 効果的なインシデント後の分析プロセスを構築します。根本原因分析には通常、以下を含める必要があります

- 影響分析 - このインシデントによって影響を受けたシステム、内部プロセス、エンドユーザーを特定し、発生した可能性のある財務的影響があれば併せて記録します。

- 根本原因と解決策 - イベントの根本原因分析を実施し、将来同じシナリオの再発を防ぐためのガードレールを実装する機会を特定します。

- モニタリングとアラーム - 設定されたメトリクスとアラームのしきい値が正しいシグナルを報告しているか、また潜在的なインシデントを防止する機会があるかを特定します。

- アクションアイテムと学習 - アクションアイテムに担当者を割り当て、フォローアップを行います。インシデントから得られた学習を製品ライフサイクルに組み込み、将来の障害を回避するためのフィードバックメカニズムを確立することが重要です。 

## サービスレベル目標と主要メトリクス

 SLI (Service Level Indicator) は実際の測定値/メトリクスです。例としては、ミリ秒単位のレスポンス時間、システム稼働率のパーセンテージ、100 万リクエストあたりのエラー率、1 秒あたりのリクエスト数で表されるスループット、リソース使用率 (CPU、メモリなど) が含まれます。

SLO (Service Level Objectives) は、SLI を使用して設定される目標値です。これらは「良好なサービス」が何を意味するかを定義します。例えば、リクエストの 95% が 200ms 未満で完了する、月間稼働率 99.9%、30 日間のエラー率が 0.1% 未満などがあります。SLI と SLO の関係は以下のように定義できます。 

         SLI (metric) + Target + Time Window = SLO
         Example: Response time (SLI) + Under 200ms + Measured over 30 days = SLO

  


#### SLI と SLO のベストプラクティスは以下のとおりです
- SLO に対する SMART フレームワークを確立します
    - Specific（具体的）: 明確なメトリクスとしきい値（「200ms 未満の応答時間」）。
    - Measurable（測定可能）: モニタリングツールで追跡できる。
    - Achievable（達成可能）: システム機能を考慮して現実的である。
    - Relevant（関連性）: ユーザーエクスペリエンスにとって重要である。
    - Time-bound（期限付き）: 定義された期間（例: 30 日間）にわたって測定される。

- ユーザーエクスペリエンスに直接影響を与える SLI を選択します。

- ビジネスニーズに基づいて現実的な SLO ターゲットを設定します。

- 定期的な監視と調整。

- 明確なドキュメントとコミュニケーション。

- 必要に応じて、異なるサービス階層に対して異なる SLO を設定します。

- 次のような主要なメトリクスを特定します

- レイテンシー: システムがリクエストに応答するまでの時間を測定し、成功とエラーの両方のレイテンシーを追跡します。
    - トラフィック: システムを通過するリクエストまたはデータの量を監視し、使用パターンとスケール要件を把握します。
    - エラー: システム内で発生するエラーの頻度とタイプを追跡します。
    - 飽和度: CPU やメモリなどの重要なリソースの使用率を監視し、潜在的なボトルネックを特定します。

SLO ドキュメントの例を以下に示します。

    Service: User Authentication API
    SLO: 99.9% of authentication requests will complete in under 500ms
    Measurement Window: Rolling 30-day period
    SLI: Response time measured at server
    Exclusions: Planned maintenance windows



## キャパシティプランニングとスケーリング
キャパシティプランニングとイベント準備は、システムの信頼性を確保するために不可欠な要素です。 

#### ベストプラクティスの一部 

- 予想されるユーザートラフィックパターン、ユーザーの地理的分布、ターゲット AWS リージョン、イベントのピーク時間などの主要なコンポーネントを含む包括的なイベントカレンダーを実装します。

- システムスケーリング検証、パフォーマンスベンチマーク、容量しきい値テストを含むイベント準備テストを実施します。

- バックアップと復元手順、リージョン切り替えランブック、インシデント対応プロトコル、軽減手順などのフェイルオーバーメカニズムを検証します。 


## インフラストラクチャ管理のための自動化とスクリプト
 自動化は、インフラストラクチャの効率的な運用において重要です。自動化により、より信頼性が高く、スケーラブルで効率的なインフラストラクチャが実現され、チームは日常的なメンテナンスではなく戦略的な取り組みに集中できるようになります。自動化のメリットには次のようなものがあります

* 人間の介入をほとんどまたはまったく必要とせずに、システムの信頼性を向上させます。

* トラフィックと需要に応じてアプリケーションを自動スケールできるようにすることで、スケーラビリティが向上します。

* 迅速かつ自動化されたインシデント解決、エラー率の削減、MTBF (平均故障間隔) の改善。

* 運用コストの削減とリソース使用率の向上。 

#### 主要な自動化戦略には以下が含まれます

* Infrastructure as Code (IaC) の実装とインフラストラクチャ変更のバージョン管理。

* 自動テストとロールバック機能を含む継続的インテグレーション/継続的デプロイメント (CI/CD)。

* 統合されたヘルスチェックと自動復旧機能を備えたセルフヒーリングシステム。


## SRE チームのための監視とアラート戦略
効果的な監視とアラートは、Site Reliability Engineering (SRE) チームが分散型のマイクロサービスベースのアプリケーションの信頼性とパフォーマンスを積極的に確保するために不可欠です。潜在的に数百のマイクロサービスを持つ分散システムの監視は困難な場合があります。アーキテクチャの複雑さに関係なく、主要なメトリクスを特定し、それらがアプリケーションのパフォーマンスとユーザーエクスペリエンスに与える影響から逆算して作業を開始する必要があります。 

#### 包括的なテレメトリの収集 
- 収集されるテレメトリデータが、各アーキテクチャコンポーネントの健全性とパフォーマンスに関する十分な洞察を提供していることを確認します。収集されたデータの関連性と実用性を継続的に評価します。

#### アラート戦略

- アクション可能なアラートの定義 - テレメトリデータから生成されるアラートはアクション可能である必要があり、SRE チームが問題を迅速に特定して対応できるようにします。アラートは、意味があり潜在的な問題を予測できる閾値とパターンに基づいている必要があります。

- アラートのルーティングとエスカレーションの最適化 - 明確に定義されたアラートのルーティングとエスカレーションプロセスを実装し、重要な問題について適切なチームと担当者に確実に通知されるようにします。アラートのルーティングを継続的に見直して改善し、応答性を向上させ、アラート疲れを最小限に抑えます。

#### ダッシュボードと可視化

- 包括的なダッシュボードの作成 - 主要な運用メトリクス、コストとキャパシティプランニングデータ、インフラストラクチャの健全性など、アプリケーションの状態を総合的に把握できるダッシュボードを開発します。ダッシュボードには、問題を効果的に予測および防止できるしきい値とインジケーターを含めるようにします。

- データドリブンな意思決定を可能にする - ダッシュボードから得られたインサイトを使用して、キャパシティプランニング、パフォーマンス最適化、インシデント対応戦略などのデータドリブンな意思決定プロセスに活用します。


## カオスエンジニアリングと実験のガイドライン

カオスエンジニアリングの目標は、アプリケーションの信頼性をテストし、障害、トラフィックの急増、その他の外部イベントなどの破壊的なイベントに対してアプリケーションがどのように応答するかを理解することです。カオスエンジニアリングは、チームがパフォーマンスのボトルネック、アプリケーションの動作を評価し、実際のシナリオで障害を修復するための戦略を実装するのに役立ちます。 

### Chaos Engineering に関するベストプラクティス 

- 小規模から始めて徐々に複雑さを増やす - これには仮説の構築が含まれます（例えば、アプリケーションのトラフィックが 30% 増加した場合、どのようなパフォーマンスになるか）。

- 定常状態を定義します。

- 実験を通じて障害を導入します。

-  システムの動作を観察し、是正的なレジリエンスアクションを実行します。

- 堅牢なモニタリングを実装する - 効果的なカオスエンジニアリングのために、ログ、メトリクス、トレースなどの関連するテレメトリデータを収集していることを確認してください。

- 常にロールバック計画を用意する - Chaos Engineering を CI/CD パイプラインに統合することで、ロールバック計画を自動化してテストできるようになります。

- 各実験から学び、調査結果を文書化し、システムの回復力を向上させ、カオスエンジニアリングを開発ライフサイクルに統合します。

これらの Chaos Engineering プラクティスを体系的に実装することで、組織はシステムの回復力を大幅に向上させ、予期しないダウンタイムを削減し、より信頼性の高いサービスを構築できます。目標は混乱を生み出すことではなく、混沌とした状況に耐えられるシステムを構築することであることを忘れないでください。


## 参考資料
- [AWS Observability Workshop](https://catalog.workshops.aws/observability/en-US)
- [AWS Observability ベストプラクティス](/observability-best-practices/ja/)
- [Amazon CloudWatch Intelligent Operations](https://aws.amazon.com/cloudwatch/features/intelligent-operations/)
- [レジリエンス分析フレームワーク](https://docs.aws.amazon.com/prescriptive-guidance/latest/resilience-analysis-framework/introduction.html)
- [AWS Fault Injection Simulator を使用したカオスエンジニアリング](https://aws.amazon.com/blogs/architecture/chaos-testing-with-aws-fault-injection-simulator-and-aws-codepipeline/) 
